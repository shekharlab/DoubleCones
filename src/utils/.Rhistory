library(Seurat)
library(Seurat)
# Change Directory to Analysis2020 Folder in the the Google Drive
#setwd("~/Google Drive File Stream/My Drive/Manuscript - Zebrafish RGC Atlas/Analysis/Analysis ")
setwd("~/Google Drive File Stream/My Drive/Research/Current/Manuscript - Zebrafish RGC Atlas/Analysis/Analysis2020/")
# Load libraries
library(Seurat)
source("utils/utilFxns.R") # Some useful functions imported from sc.R
# Load adult Seurat object and Count matrix
Count.mat <- readRDS("../CountMatrices/ConsolidatedCounts_Zfish_013020.rds")
adult <- readRDS("../Objects2020/zFish_SeuratClusteredIntegratedPruned_FinalV2_021820.rds")
# Only include cells from the full adult object with <20% mitochondrial genes
quality_cells <- colnames(adult)[adult@meta.data$percent.mt < 20]
Count.mat <- Count.mat[,quality_cells]
dim(Count.mat)
dim(adult)
adult@meta.data$percent.mt
c
# Only include cells from the full adult object with <20% mitochondrial genes
quality_cells <- colnames(adult)[adult@meta.data$percent.mt < 15]
length(quality_cells)
# Only include cells from the full adult object with <20% mitochondrial genes
quality_cells <- colnames(adult)[adult@meta.data$percent.mt < 10]
length(quality_cells)
hist(adult@meta.data$percent.mt)
hist(adult@meta.data$percent.mt,10)
# Only include cells from the full adult object with <20% mitochondrial genes
quality_cells <- colnames(adult)[adult@meta.data$percent.mt < 15]
Count.mat <- Count.mat[,quality_cells]
# Create Seurat object
####### Remove genes not expressed in at least 25 cells ########################
zFish <- CreateSeuratObject(counts = Count.mat, project = "zfishRGC", min.cells = 25, min.features = 450)
# Set QC metrics
zFish[["percent.mt"]] <- PercentageFeatureSet(zFish, pattern = "^MT-")
zFish[["percent.rps"]] <- PercentageFeatureSet(zFish, pattern = "^RPS")
zFish[["percent.rpl"]] <- PercentageFeatureSet(zFish, pattern = "^RPL")
zFish[["percent.rp"]] <- zFish[["percent.rps"]] + zFish[["percent.rpl"]]
# Change the order of factor
zFish@meta.data$orig.ident = factor(zFish@meta.data$orig.ident, levels = paste0("ZfishRGC",c(1:15)))
# Set the batch information in meta.data
batchname = as.character(zFish@meta.data$orig.ident)
batchid = rep("Batch0", length(batchname))
batchid[grep("ZfishRGC1$", batchname)] = "Batch1"
batchid[grep("ZfishRGC2", batchname)] = "Batch1"
batchid[grep("ZfishRGC3", batchname)] = "Batch2"
batchid[grep("ZfishRGC4", batchname)] = "Batch2"
batchid[grep("ZfishRGC5", batchname)] = "Batch3"
batchid[grep("ZfishRGC6", batchname)] = "Batch3"
batchid[grep("ZfishRGC7", batchname)] = "Batch3"
batchid[grep("ZfishRGC8", batchname)] = "Batch3"
batchid[grep("ZfishRGC9", batchname)] = "Batch4"
batchid[grep("ZfishRGC10", batchname)] = "Batch4"
batchid[grep("ZfishRGC11", batchname)] = "Batch5"
batchid[grep("ZfishRGC12", batchname)] = "Batch5"
batchid[grep("ZfishRGC13", batchname)] = "Batch5"
batchid[grep("ZfishRGC14", batchname)] = "Batch5"
batchid[grep("ZfishRGC15", batchname)] = "Batch5"
zFish@meta.data$batch = factor(batchid)
# Normalize the data, identify variable features, scale, run PCA
zFish <- NormalizeData(zFish, normalization.method = "LogNormalize", scale.factor = 10000)
zFish <- FindVariableFeatures(zFish, selection.method = "vst", nfeatures = 2000)
zFish <- ScaleData(zFish, features = rownames(zFish))
zFish <- RunPCA(zFish, features = VariableFeatures(object = zFish))
# Compute clusters and visualize using UMAP and tSNE
####### 40 PCs used for FindNeighbors, resolution = .5 ########################
zFish <- FindNeighbors(zFish, dims = 1:40)
zFish <- FindClusters(zFish, resolution = .5)
zFish <- RunTSNE(zFish, dims = 1:40)
zFish <- RunUMAP(zFish, dims = 1:40)
# Data integration: split object by batch number
zFish.list <- SplitObject(zFish, split.by = "batch")
# Normalize datasets and find variable features
for (i in 1:length(zFish.list)) {
print(i)
zFish.list[[i]] <- NormalizeData(zFish.list[[i]], verbose = FALSE)
zFish.list[[i]] <- FindVariableFeatures(zFish.list[[i]], selection.method = "vst",
nfeatures = 1500, verbose = FALSE)
}
# Find Integration anchors
zFish.anchors <- FindIntegrationAnchors(object.list = zFish.list, dims = 1:40)
# Integrate Data
zFish.integrated <- IntegrateData(anchorset = zFish.anchors, dims = 1:40)
# Switch to integrated assay. The variable features of this assay are automatically
# set during IntegrateData
DefaultAssay(zFish.integrated) <- "integrated"
# Run the standard workflow for visualization and clustering
####### 40 PCs used for FindNeighbors, resolution = .5 ########################
zFish.integrated <- ScaleData(zFish.integrated, verbose = FALSE)
zFish.integrated <- RunPCA(zFish.integrated, npcs = 40, verbose = FALSE)
zFish.integrated <- RunUMAP(zFish.integrated, reduction = "pca", dims = 1:40)
zFish.integrated <- RunTSNE(zFish.integrated, reduction = "pca", dims = 1:40)
zFish.integrated <- FindNeighbors(zFish.integrated, dims = 1:40)
zFish.integrated <- FindClusters(zFish.integrated, resolution = .5)
# Save integrated object
saveRDS("../Objects2020/adult_zFish_MTfiltered_81420.rds")
Idents(zFish.integrated)
Idents(adult)
table(Idents(adult)[colnames(zFish.integrated)], Idents(zFish.integrated))
# Save integrated object
saveRDS(zFish.integrated,"../Objects2020/adult_zFish_MTfiltered_81420.rds")
VlnPlot(zFish.integrated,"percent.mt")
VlnPlot(zFish.integrated,"percent.mt", pt.size=0)
# Load adult Seurat object and Count matrix
Count.mat <- readRDS("../CountMatrices/ConsolidatedCounts_Zfish_013020.rds")
# Only include cells from the full adult object with <20% mitochondrial genes
quality_cells <- colnames(adult)[adult@meta.data$percent.mt < 10]
Count.mat <- Count.mat[,quality_cells]
# Create Seurat object
####### Remove genes not expressed in at least 25 cells ########################
zFish <- CreateSeuratObject(counts = Count.mat, project = "zfishRGC", min.cells = 25, min.features = 450)
# Set QC metrics
zFish[["percent.mt"]] <- PercentageFeatureSet(zFish, pattern = "^MT-")
zFish[["percent.rps"]] <- PercentageFeatureSet(zFish, pattern = "^RPS")
zFish[["percent.rpl"]] <- PercentageFeatureSet(zFish, pattern = "^RPL")
zFish[["percent.rp"]] <- zFish[["percent.rps"]] + zFish[["percent.rpl"]]
# Change the order of factor
zFish@meta.data$orig.ident = factor(zFish@meta.data$orig.ident, levels = paste0("ZfishRGC",c(1:15)))
# Set the batch information in meta.data
batchname = as.character(zFish@meta.data$orig.ident)
batchid = rep("Batch0", length(batchname))
batchid[grep("ZfishRGC1$", batchname)] = "Batch1"
batchid[grep("ZfishRGC2", batchname)] = "Batch1"
batchid[grep("ZfishRGC3", batchname)] = "Batch2"
batchid[grep("ZfishRGC4", batchname)] = "Batch2"
batchid[grep("ZfishRGC5", batchname)] = "Batch3"
batchid[grep("ZfishRGC6", batchname)] = "Batch3"
batchid[grep("ZfishRGC7", batchname)] = "Batch3"
batchid[grep("ZfishRGC8", batchname)] = "Batch3"
batchid[grep("ZfishRGC9", batchname)] = "Batch4"
batchid[grep("ZfishRGC10", batchname)] = "Batch4"
batchid[grep("ZfishRGC11", batchname)] = "Batch5"
batchid[grep("ZfishRGC12", batchname)] = "Batch5"
batchid[grep("ZfishRGC13", batchname)] = "Batch5"
batchid[grep("ZfishRGC14", batchname)] = "Batch5"
batchid[grep("ZfishRGC15", batchname)] = "Batch5"
zFish@meta.data$batch = factor(batchid)
# Normalize the data, identify variable features, scale, run PCA
zFish <- NormalizeData(zFish, normalization.method = "LogNormalize", scale.factor = 10000)
zFish <- FindVariableFeatures(zFish, selection.method = "vst", nfeatures = 2000)
zFish <- ScaleData(zFish, features = rownames(zFish))
zFish <- RunPCA(zFish, features = VariableFeatures(object = zFish))
# Compute clusters and visualize using UMAP and tSNE
####### 40 PCs used for FindNeighbors, resolution = .5 ########################
zFish <- FindNeighbors(zFish, dims = 1:40)
zFish <- FindClusters(zFish, resolution = .5)
zFish <- RunTSNE(zFish, dims = 1:40)
zFish <- RunUMAP(zFish, dims = 1:40)
# Data integration: split object by batch number
zFish.list <- SplitObject(zFish, split.by = "batch")
# Normalize datasets and find variable features
for (i in 1:length(zFish.list)) {
print(i)
zFish.list[[i]] <- NormalizeData(zFish.list[[i]], verbose = FALSE)
zFish.list[[i]] <- FindVariableFeatures(zFish.list[[i]], selection.method = "vst",
nfeatures = 1500, verbose = FALSE)
}
# Find Integration anchors
zFish.anchors <- FindIntegrationAnchors(object.list = zFish.list, dims = 1:40)
# Integrate Data
zFish.integrated <- IntegrateData(anchorset = zFish.anchors, dims = 1:40)
# Switch to integrated assay. The variable features of this assay are automatically
# set during IntegrateData
DefaultAssay(zFish.integrated) <- "integrated"
# Run the standard workflow for visualization and clustering
####### 40 PCs used for FindNeighbors, resolution = .5 ########################
zFish.integrated <- ScaleData(zFish.integrated, verbose = FALSE)
zFish.integrated <- RunPCA(zFish.integrated, npcs = 40, verbose = FALSE)
zFish.integrated <- RunUMAP(zFish.integrated, reduction = "pca", dims = 1:40)
zFish.integrated <- RunTSNE(zFish.integrated, reduction = "pca", dims = 1:40)
zFish.integrated <- FindNeighbors(zFish.integrated, dims = 1:40)
zFish.integrated <- FindClusters(zFish.integrated, resolution = .5)
# Save integrated object
saveRDS(zFish.integrated,"../Objects2020/adult_zFish_MTfiltered_cutoff10_81420.rds")
dim(zFish.integrated)
dim(adult)
6/32
C_A0 = c(4,13,12,18,7,8,27,8)
C_A = c(3.5, 11, 9, 11, 3.5, 3, 7, 1)
tau = c(10, 7, 4, 3, 2, 4, 12, 23)
X_A = (C_A0 - C_A)/(C_A0)
X_A
mrA = (C_A0 - C_A)/tau
mrA
y = 0.5*C_A0/mrA
y
plot(y, X_A)
plot(X_A,y)
library(biomaRt)
listEnsembl()
ensembl = useEnsembl(biomart = "ensembl")
head(listDatasets(ensembl))
# Ferret
grep("Ferret",listDatasets(ensembl)$description)
listDatasets(ensembl)[111,]
ensembl_ferret = useEnsembl(biomart="ensembl", dataset="mpfuro_gene_ensembl")
head(listFilters(ensembl_ferret))
head(listAttributes(ensembl_ferret))
# You will have to look in the features and get the columns corresponding to external gene name
ferret_table = getBM(attributes=c('ensembl_gene_id','external_gene_name'), mart = ensembl_ferret)
type(mart)
class(mart)
class(ensembl_ferret)
packageVersion("data.table")
R.version
clear
25 + 74
25 * 74
48 / 6
for (i in 1:250){
print(2*i)
}
for (i in 1:250){
print(2*(i-1) + 1)
Sys.sleep(0.4)
}
x = c(); y = c()
for (theta = seq(0,2*pi, length.out = 50)){
for (theta in seq(0,2*pi, length.out = 50)){
x = 5*cos(theta); y = 5*sin(theta);
}
plot(x, y)
x
x = c(); y = c()
for (theta in seq(0,2*pi, length.out = 50)){
x = c(x,5*cos(theta)); y = c(y,5*sin(theta));
}
plot(x,y)
x
y
length(x)
length(y)
plot(x,y)
plot(x,x)
plot(x,y)
a = read.csv("~/Downloads/cell_by_gene.csv")
dim(a)
head(a)
a[,"Opn4"]
sum(a[,"Opn4"])
sum(a[,"Opn4"] > 20)
sum(a[,"Opn4"] > 10)
sum(a[,"Opn4"] > 12)
dim(A)
sum(a[,"Opn4"] > 1)
plot(a[,"Opn4"],a[,"Eomes"])
cor(a[,"Opn4"],a[,"Eomes"])
cor(a[,"Spp1"],a[,"Foxp2"])
cor(a[,"Satb2"],a[,"Neurod2"])
plot(a[,"Satb2"],a[,"Neurod2"])
plot(a[,"Eomes"],a[,"Neurod2"])
cor(a[,"Eomes"],a[,"Neurod2"])
plot(a[,"Eomes"],a[,"Cartpt"])
cor(a[,"Eomes"],a[,"Cartpt"])
cor(a[,"Eomes"],a[,"Cartpt"], method = "Spearman")
cor(a[,"Eomes"],a[,"Cartpt"], method = "spearman")
cor(log(a[,"Eomes"]+1),log(a[,"Cartpt"]+1))
cor(log(a[,"Eomes"]+1),log(a[,"Neurod2"]+1))
cor(log(a[,"Satb2"]+1),log(a[,"Neurod2"]+1))
colnames(a)
head(a)
plot(a[,"Eomes"],a[,"Slc17a6"])
plot(a[,"Rbpms"],a[,"Slc17a6"])
cor(a[,"Rbpms"],a[,"Slc17a6"])
cor(a[,"Rbpms"],a[,"Pou4f2"])
plot(a[,"Rbpms"],a[,"Pou4f2"])
plot(a[,"Rbpms"],a[,"Pou4f1"])
plot(a[,"Ilrapl2"],a[,"Opn4"])
plot(a[,"Il1rapl2"],a[,"Opn4"])
plot(a[,"Tbx20"],a[,"Opn4"])
plot(a[,"Pde1a"],a[,"Irx4"])
plot(a[,"Fam19a4"],a[,"Gpr88"])
plot(a[,"Col25a1"],a[,"Gpr88"])
plot(a[,"Col25a1"],a[,"Mmp17"])
plot(a[,"Foxp2"],a[,"Tbr1"])
plot(a[,"Foxp2"],a[,"Cartpt"])
plot(a[,"Foxp2"],a[,"Spp1"])
plot(a[,"Foxp2"],a[,"Tusc5"])
plot(a[,"Foxp2"],a[,"Trarg1"])
library(Seurat)
install.packages("Seurat")
install.packages("Seurat")
library(Seurat)
install.packages("Seurat")
install.packages("Seurat")
library(Seurat)
x=0.3
x^5/(1-x)^2
x=0.1
x^5/(1-x)^2
x=0.9
x^5/(1-x)^2
x=0.49
x^5/(1-x)^2
x=0.66
x^5/(1-x)^2
x=0.59
x^5/(1-x)^2
x=0.6
x^5/(1-x)^2
x^5/((1-x)^2 * (1+1.5*x)^3)
x=0.6
x^5/((1-x)^2 * (1+1.5*x)^3)
x=0.7
x^5/((1-x)^2 * (1+1.5*x)^3)
x=0.8
x^5/((1-x)^2 * (1+1.5*x)^3)
x=0.75
x^5/((1-x)^2 * (1+1.5*x)^3)
x=0.76
x^5/((1-x)^2 * (1+1.5*x)^3)
x=0.06
x^5/((1-x)^2 * (1+1.5*x)^3)
x = c(0,0.01,1)
x
setwd("/Volumes/GoogleDrive/My Drive/Research/Current/Beta2KO")
library(Seurat)
setwd("/Volumes/GoogleDrive/My Drive/Research/Current/Beta2KO")
rgc_atlas = readRDS("rgcP56_Seurat_2022.rds")
rgc_atlas@assays$RNA[1,]
rgc_atlas = readRDS("~/Google Drive/My Drive/Berkeley Lab/Data/RGC development/FinalObjects/rgc_atlas_190911_withP56.rds")
RGC_mat = rgc_atlas@count.data
a=colSums(RGC_mat)
plot(RGC_mat["Rbpms",],a)
plot(a,RGC_mat["Rbpms",])
cor(a,RGC_mat["Rbpms",])
cor(a,RGC_mat["Slc17a6",])
cor(a,RGC_mat["Gapdh",])
cor(a,RGC_mat["Nefl",])
df = data.frame(N_tot = a, Rbpms = RGC_mat["Rbpms",], Nefl = RGC_mat["Nefl",])
library(ggplot2)
ggplot(data = df) + geom_scatter(x=N_tot, y=Rbpms)
ggplot(data = df) + geom_point(x=N_tot, y=Rbpms)
ggplot(data = df) + geom_scatter(aes(x=N_tot, y=Rbpms))
ggplot(data = df) + geom_point(aes(x=N_tot, y=Rbpms))
ggplot(data = df) + geom_point(aes(x=N_tot, y=Rbpms)) + theme_classic()
ggplot(data = df) + geom_point(aes(x=N_tot, y=Nefl)) + theme_classic()
0.67^2
dim(RGC_mat)
sum(RGC_mat == 0)
864584942/(27933*35699)
rgc_atlas@var.genes
A = RGC_mat[rgc_atlas@var.genes,]
sum(A==0)
27821324 /(nrow(A)*ncol(A))
setwd("/Volumes/GoogleDrive/My Drive/Research/Current/Beta2KO")
library(Seurat)
library(ggplot2)
library(reshape2)
library(dplyr)
require(xgboost)
source("/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/utilFxns.R")
source("/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/plottingFxns.R")
source("/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/xgboost_train.R")
rgcP56 = readRDS("rgcP56_Seurat_2022.rds")
rgcP5 = readRDS("rgcP5_Seurat.rds")
rgcP5 = FindVariableFeatures(rgcP5, selection.method = "vst", nfeatures = 3000)
rgcP56 = FindVariableFeatures(rgcP56, selection.method = "vst", nfeatures = 3000)
rgc.list = list(rgcP56, rgcP5)
# Find Correspondence Between P5 and P56
# Train model
Idents(rgcP56) = "old_clusters"
common.features = intersect(VariableFeatures(rgcP56),
VariableFeatures(rgcP5))
common.features
VariableFeatures(rgcP5)
rgcP5 = FindVariableFeatures(rgcP5, selection.method = "vst", nfeatures = 3000)
rgcP5 = readRDS("rgcP5_Seurat.rds")
DefaultAssay(rgcP56) = "RNA"
DefaultAssay(rgcP5) = "RNA"
rgcP5 = FindVariableFeatures(rgcP5, selection.method = "vst", nfeatures = 3000)
rgcP56 = FindVariableFeatures(rgcP56, selection.method = "vst", nfeatures = 3000)
# Find Correspondence Between P5 and P56
# Train model
Idents(rgcP56) = "old_clusters"
common.features = intersect(VariableFeatures(rgcP56),
VariableFeatures(rgcP5))
common.features
rgcP56@meta.data$old_clusters = factor(rgcP56@meta.data$old_clusters)
bst_model = TrainModel(object = rgcP56,
training_genes = common.features,
train_ident = "old_clusters",
do.scale = FALSE)
rgc_conf <- BuildConfusionMatrix(test = rgcP56, model = bst_model, test_ident = "old_clusters")
rgc_conf
colnames(rgc_conf)
rownames(rgc_conf)
test = rgcP56
model = bst_model
test_ident = "old_clusters"
scale.by.model = FALSE
genes.use <- model$bst_model$feature_names
test_data = test@assays$RNA@data[genes.use,]
test_data = as.matrix(test_data)
test_id = Idents(test)
train_id = Idents(train)
test_ident = "old_clusters"
scale = FALSE; scale.by.model = FALSE; assay = "RNA"; slot = "data"
genes.use <- model$bst_model$feature_names
train_id = factor(colnames(model$test_mat))
test_data = as.matrix(slot(test@assays[[assay]], slot))
train_id
colnames(model$test_mat)
model$test_mat
colnames(model$test_mat)
bst_model$test_mat
dim(bst_model$test_mat)
colnames(bst_model$test_mat)
colnames(bst_model$test_mat) = as.numeric(colnames(bst_model$test_mat))
rownames(bst_model$test_mat) = as.numeric(rownames(bst_model$test_mat))
colnames(bst_model$test_mat)
factor(colnames(bst_model$test_mat))
levels = unique(colnames(model$test_mat))
unique(colnames(model$test_mat))
source('/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/xgboost_train.R', echo=TRUE)
source("/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/xgboost_train.R")
rgc_conf <- BuildConfusionMatrix(test = rgcP56, model = bst_model, test_ident = "old_clusters")
rgc_conf
MakePrettyConfusionMatrix(rgc_conf, xlab.use = "Predicted Label", ylab.use = "P5 clusters")
rgc_conf <- BuildConfusionMatrix(test = rgcP5, model = bst_model, test_ident = "seurat_clusters")
MakePrettyConfusionMatrix(rgc_conf, xlab.use = "Predicted P56 Label", ylab.use = "P5 clusters")
C = table(rgcP5@meta.data$seurat_clusters, rgcP5@meta.data$adult_type)
MakePrettyConfusionMatrix(C, xlab.use = "Adult (P56) type", ylab.use = "P5 clusters")
MakePrettyConfusionMatrix(rgc_conf, xlab.use = "Predicted P56 Label", ylab.use = "P5 clusters")
MakePrettyConfusionMatrix(C, xlab.use = "Predicted P56 Label", ylab.use = "P5 clusters")
rgc_conf
C
rgc_conf[1:45,1:45]
dim(rgc_conf)
rgc_conf[1:40,1:45]
rgc_conf[1:40,as.character(1:45)]
dim(C)
C
# Consistency
A = rgc_conf[,as.character(1:45)]; B = C[1:45,1:45]
dim(C)
# Consistency
A = rgc_conf[,as.character(1:45)]; B = C[1:40,1:45]
help(scale)
A = t(scale(t(A), center=rowSums(A), scale=FALSE))
A
# Consistency
A = rgc_conf[,as.character(1:45)]; B = C[1:40,1:45]
A = t(scale(t(A), center=FALSE, scale=rowSums(A)))
A
rowSums(A)
B =  t(scale(t(B), center=FALSE, scale=rowSums(B)))
plot(A,B)
as.numeric(A)
plot(as.numeric(A),as.numeric(B))
bst_model2 = TrainModel(object = rgcP56,
training_genes = common.features,
train_ident = "old_clusters", do.scale = TRUE)
rgc_conf2 <- BuildConfusionMatrix(test = rgcP5, model = bst_model, test_ident = "seurat_clusters",
scale = TRUE, scale.by.model = TRUE)
dim(bst_model2$test_mat)
rgc_conf2 <- BuildConfusionMatrix(test = rgcP5, model = bst_model2, test_ident = "seurat_clusters",
scale = TRUE, scale.by.model = TRUE)
MakePrettyConfusionMatrix(rgc_conf2, xlab.use = "Predicted P56 Label", ylab.use = "P5 clusters")
setwd("/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils")
install.packages("paletteer")
source('/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/KS_fxns.R')
if (feature1 %in% rownames(object@data)){
F1 = object@data[feature1,]
} else {
F1 = object@data.info[,feature1]
}
common.features = intersect(VariableFeatures(rgcP56),
VariableFeatures(rgcP5))
# Find Correspondence Between P5 and P56
# Train model (KS method)
Idents(rgcP56) = "old_clusters"; Idents(rgcP5) = "seurat_clusters"
DefaultAssay(rgcP56) = "RNA"; DefaultAssay(rgcP5) = "RNA"
common.features
scale.mean = Matrix::rowMeans(rgcP56@data[common.features,])
scale.mean = Matrix::rowMeans(rgcP56@assays$RNA@data[common.features,])
scale.mean = Matrix::rowMeans(train_object@assays$RNA@data[common.features,])
train_object = rgcP56; test_object = rgcP5
scale.mean = Matrix::rowMeans(train_object@assays$RNA@data[common.features,])
scale.var = apply(as.matrix(train_object@ssays$RNA@data[common.features, ]), 1, sd)
scale.var = apply(as.matrix(train_object@assays$RNA@data[common.features, ]), 1, sd)
source('/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/KS_fxns.R')
# Train on P56
xgboost_train = XGBoost_train_KS(train_object0 = train_object, var.genes = common.features, do.scale=TRUE,
scale.mean = scale.mean, scale.var = scale.var,   min.val = -5, max.val = 7)
source('/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/KS_fxns.R')
# Train on P56
xgboost_train = XGBoost_train_KS(train_object0 = train_object, var.genes = common.features, do.scale=TRUE,
scale.mean = scale.mean, scale.var = scale.var,   min.val = -5, max.val = 7)
install.packages("philentropy")
source('/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/KS_fxns.R')
# Train on P56
xgboost_train = XGBoost_train_KS(train_object0 = train_object, var.genes = common.features, do.scale=TRUE,
scale.mean = scale.mean, scale.var = scale.var,   min.val = -5, max.val = 7)
source('/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/KS_fxns.R')
source('/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/KS_fxns.R')
# Train on P56
xgboost_train = XGBoost_train_KS(train_object0 = train_object, var.genes = common.features, do.scale=TRUE,
scale.mean = scale.mean, scale.var = scale.var,   min.val = -5, max.val = 7)
help("WhichCells")
source('/Volumes/GoogleDrive/My Drive/Berkeley Lab/Shekhar Lab/Projects/Evolution of Cell Types/Analysis/utils/KS_fxns.R')
# Train on P56
xgboost_train = XGBoost_train_KS(train_object0 = train_object, var.genes = common.features, do.scale=TRUE,
scale.mean = scale.mean, scale.var = scale.var,   min.val = -5, max.val = 7)
xgboost_train
# Tran on P5
# Train test object
xgboost_test = XGBoost_train_KS(train_object0 = test_object, var.genes = common.features, do.scale=TRUE,
scale.mean = scale.mean, scale.var = scale.var,   min.val = -5, max.val = 7)
# Tran on P5
# Train test object
xgboost_test = XGBoost_train_KS(train_object0 = test_object, var.genes = common.features, do.scale=TRUE,
scale.mean = scale.mean, scale.var = scale.var,   min.val = -5, max.val = 7)
